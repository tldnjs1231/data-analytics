{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FDguohetpVyB",
    "outputId": "928e065e-1cea-4aab-d3d1-11cc1df4cd3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictioin accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier # 분류 알고리즘 (비지도/지도학습 중 지도학습 안에 분류/회귀)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# 데이터셋을 분할하지 않고 예측하는 경우(전체 데이터를 학습, test_size 0%)\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "\n",
    "dt_clf.fit(train_data, train_label)\n",
    "pred = dt_clf.predict(train_data) # 학습 데이터로 예측 진행\n",
    "\n",
    "print('predictioin accuracy:', accuracy_score(train_label, pred))\n",
    "\n",
    "# 데이터를 분할하지 않으면 학습/예측의 의미가 없음(정확도 1.0; 100%)\n",
    "# 테스트 데이터로 예측을 해주어야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olzTWzV7SOqY"
   },
   "source": [
    "# cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xy8P3O6SRNk"
   },
   "source": [
    "- 교차검증을 쉽게 하도록 도와주는 API\n",
    "- 폴드 세트 추출, 학습/예측, 평가를 한 번에 수행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KAslSqnSReNj"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# feature 데이터와 정답 데이터를 변수에 저장\n",
    "data = iris.data # feature\n",
    "label = iris.target # target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156) # 알고리즘 객체 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jiJrfXVSWYB"
   },
   "source": [
    "## cross_val_score 이용한 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BEh0rsAHSKCh"
   },
   "outputs": [],
   "source": [
    "# cross_val_score import\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SkniHKhFm-FB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold val accuracy: [0.98 0.94 0.98]\n",
      "Avg val accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score의 파라미터\n",
    "\n",
    "# estimator: 구현하고자 하는 모델/어떤 알고리즘을 사용할 것인지(분류, 회귀)\n",
    "# X(대문자): 데이터 세트\n",
    "# y(소문자): label 데이터 세트\n",
    "# scoring: 검증 지표(성능 평가 지표)\n",
    "# cv: 교차 검증의 fold 숫자(몇 번의 교차 검증을 진행할 것인지)\n",
    "\n",
    "scores = cross_val_score(estimator=dt_clf,\n",
    "                        X=data, y=label,\n",
    "                        cv=3, scoring='accuracy')\n",
    "\n",
    "# 'Fold val accuracy:' 교차검증한 결과값을 출력\n",
    "print('Fold val accuracy:', scores)\n",
    "\n",
    "# 'Avg val accuracy:' 교차검증한 결과값의 평균을 출력 -> 최종 accuracy 값\n",
    "print('Avg val accuracy:', np.round(np.mean(scores), 3))\n",
    "\n",
    "# 교차검증을 한다고 해서 꼭 정확도가 더 높게 나오는 것은 아님\n",
    "# 머신러닝의 목표는 테스트 데이터에서도 좋은 성능을 유지하는 모델을 만드는 것\n",
    "# 따라서 이런저런 시도를 많이 해볼 필요가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOFRSApIWZnV"
   },
   "source": [
    "## GridSearchCV\n",
    "- 알고리즘에 파라미터를 삽입하여 파라미터에 맞게 여러 번 교차검증을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Abs8o1tFWeIw"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# 데이터셋을 x_train, x_test, y_train, y_test로 분리, test_size: 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data,\n",
    "                                                   iris.target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o1me77anpVyW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (120,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train, y_train의 크기 출력\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xX_lbgVzWf5_",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # 알고리즘 선택\n",
    "from sklearn.model_selection import GridSearchCV # 모든 검증 함수는 model_selection 안에 존재\n",
    "\n",
    "dtree = DecisionTreeClassifier() # 알고리즘 객체 생성\n",
    "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]} # dictionary 형태\n",
    "\n",
    "\n",
    "# GridSearchCV의 파라미터\n",
    "\n",
    "# estimator: 구현하고자 하는 모델\n",
    "# param_grid: 모델의 튜닝에 사용될 파라미터 정보(dictionary 형태)\n",
    "# scoring: 검증 지표(성능 평가 지표)\n",
    "# cv: 교차 검증의 fold 숫자\n",
    "# refit: 최적의 파라미터로 모델 재학습 여부(default: True)\n",
    "\n",
    "# GridSearchCV 교차검증\n",
    "grid_dtree = GridSearchCV(dtree, # 첫 번째 인자 default: estimator\n",
    "                         param_grid=parameters,\n",
    "                         cv=3, refit=True)\n",
    "\n",
    "# scoring defalut for classification -> sklearn.metrics.accuracy_score\n",
    "# scoring default for regression -> sklearn.metrics.r2_score\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "# return 값: grid_dtree.cv_results_(결과값이 저장되는 변수 cv_results_)\n",
    "grid_dtree.fit(x_train, y_train)\n",
    "\n",
    "# 교차 검증 없이 학습을 진행한 경우:\n",
    "# dtree 객체 선언 -> dtree.fit(x_train, y_train)\n",
    "\n",
    "# GridSearchCV 교차 검증 진행한 경우:\n",
    "# dtree 객체 선언 -> grid_dtree = GridSearchCV(dtree, ...) -> grid_dtree.fit(x_train, y_train)\n",
    "# 기존에 선언된 객체에 교차 검증 함수를 한 번 더 씌워서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9evdegx1WiDA",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.675000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.675000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.966667                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.966667                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.675              0.675              0.675  \n",
       "1              0.675              0.675              0.675  \n",
       "2              0.925              1.000              0.950  \n",
       "3              0.925              1.000              0.950  \n",
       "4              0.925              1.000              0.975  \n",
       "5              0.925              1.000              0.975  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# grid_dtree.cv_results_ 값을 scores_df(데이터프레임)에 저장\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "\n",
    "# scores_df의 확인하고 싶은 column만 추출\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\n",
    "\n",
    "# max_depth 3, min_samples_split 2 or 3일 때 best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m1V6hvCGpVya"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameter: {'max_depth': 3, 'min_samples_split': 2}\n",
      "Max accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# 최적의 파라미터, 최고의 정확도 확인\n",
    "print('Optimal parameter:', grid_dtree.best_params_) # best_params_: 최적의 파라미터 저장\n",
    "print(f'Max accuracy: {grid_dtree.best_score_:.4f}') # best_score_: 최고 스코어 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lD2EZ6BjWjvs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score # 성능측정과 관련된 함수는 대부분 metrics 안에 존재\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "pred = grid_dtree.predict(x_test)\n",
    "\n",
    "# 정확도 측정값을 accur에 저장\n",
    "accur = accuracy_score(y_test, pred) # test의 정답 데이터와 예측 결과를 비교\n",
    "print(f'Test dataset accuracy: {accur:.4f}')\n",
    "\n",
    "# 학습 데이터 Max accuracy 0.9667, 테스트 데이터 accuracy 0.9333\n",
    "# 테스트 데이터도 비슷한 성능 반환 -> 교차 검증이 잘 이루어짐\n",
    "\n",
    "# 데이터가 너무 적거나 과적합의 가능성이 있는 경우,\n",
    "# 즉 학습 데이터의 accuracy는 높으나 테스트 데이터의 accuracy가 현저히 낮은 경우,\n",
    "# 교차 검증을 통해 최적의 파라미터를 찾아보는 것이 좋은 방법"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_교차검증_하이퍼파라미터튜닝-문제.ipynb",
   "provenance": [
    {
     "file_id": "1V5H8kQ6ksDwCukD0y4IsKOkobkwqSYOO",
     "timestamp": 1629510576866
    },
    {
     "file_id": "1LaLTg07w7UuCbxPyXY9N3UcRbZXPup4l",
     "timestamp": 1605836296074
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
